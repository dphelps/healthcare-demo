{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielcphelps/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sqlite3\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# used for train/test splits\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# used to impute mean for data\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "# logistic regression is our model of choice\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "# used to calculate AUROC/accuracy\n",
    "from sklearn import metrics\n",
    "\n",
    "# used to create confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Connect to MIMIC\n",
    "# be sure to add the password as appropriate!\n",
    "con = psycopg2.connect(dbname='MIMIC', user='workshop', password=''\n",
    "                       , host='<xxxxx>.amazonaws.com'\n",
    "                       , port=5432)\n",
    "cur = con.cursor()\n",
    "cur.execute('SET search_path to ''mimiciii_workshop''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "DatabaseError",
     "evalue": "Execution failed on sql '\nwith ce as\n(\n  select\n    icustay_id, charttime, itemid, valuenum\n  from chartevents\n  -- specify what data we want from chartevents\n  where itemid in\n  (\n  211, -- Heart Rate\n  618, --\tRespiratory Rate\n  615 --\tResp Rate (Total)\n  )\n  -- how did we know heart rates were stored using ITEMID 211? Simple, we looked in D_ITEMS!\n  -- Try it for yourself: select * from d_items where lower(label) like '%heart rate%'\n)\nselect\n  -- ICUSTAY_ID identifies each unique patient ICU stay\n  -- note that if the same person stays in the ICU more than once, each stay would have a *different* ICUSTAY_ID\n  -- however, since it's the same person, all those stays would have the same SUBJECT_ID\n  ie.icustay_id\n\n  -- this is the outcome of interest: in-hospital mortality\n  , max(adm.HOSPITAL_EXPIRE_FLAG) as OUTCOME\n\n  -- this is a case statement - essentially an \"if, else\" clause\n  , min(\n      case\n        -- if the itemid is 211\n        when itemid = 211\n          -- then return the actual value stored in VALUENUM\n          then valuenum\n        -- otherwise, return 'null', which is SQL standard for an empty value\n        else null\n      -- end the case statement\n      end\n    ) as HeartRate_Min\n\n    -- note we wrapped the above in \"min()\"\n    -- this takes the minimum of all values inside, and *ignores* nulls\n    -- by calling this on our case statement, we are ignoring all values except those with ITEMID = 211\n    -- since ITEMID 211 are heart rates, we take the minimum of only heart rates\n\n  , max(case when itemid = 211 then valuenum else null end) as HeartRate_Max\n  , min(case when itemid in (615,618) then valuenum else null end) as RespRate_Min\n  , max(case when itemid in (615,618) then valuenum else null end) as RespRate_Max\nfrom icustays ie\n\n-- join to the admissions table to get hospital outcome\ninner join admissions adm\n  on ie.hadm_id = adm.hadm_id\n\n-- join to the chartevents table to get the observations\nleft join ce\n  -- match the tables on the patient identifier\n  on ie.icustay_id = ce.icustay_id\n  -- and require that the observation be made after the patient is admitted to the ICU\n  and ce.charttime >= ie.intime\n  -- and *before* their admission time + 1 day, i.e. the observation must be made on their first day in the ICU\n  and ce.charttime <= ie.intime + interval '1' day\ngroup by ie.icustay_id\norder by ie.icustay_id\n': near \"'1'\": syntax error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-9bffdfabbef0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m \"\"\"\n\u001b[1;32m     64\u001b[0m \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msqlite3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/danielcphelps/Boxcryptor/Google Drive/daniel.c.phelps/Research/HealthcareAnalytics/mimic-workshop/data/mimicdata.sqlite'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_sql_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/danielcphelps/anaconda/lib/python2.7/site-packages/pandas/io/sql.pyc\u001b[0m in \u001b[0;36mread_sql_query\u001b[0;34m(sql, con, index_col, coerce_float, params, parse_dates, chunksize)\u001b[0m\n\u001b[1;32m    427\u001b[0m     return pandas_sql.read_query(\n\u001b[1;32m    428\u001b[0m         \u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoerce_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoerce_float\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m         parse_dates=parse_dates, chunksize=chunksize)\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/danielcphelps/anaconda/lib/python2.7/site-packages/pandas/io/sql.pyc\u001b[0m in \u001b[0;36mread_query\u001b[0;34m(self, sql, index_col, coerce_float, params, parse_dates, chunksize)\u001b[0m\n\u001b[1;32m   1569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1570\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1571\u001b[0;31m         \u001b[0mcursor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1572\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcol_desc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol_desc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/danielcphelps/anaconda/lib/python2.7/site-packages/pandas/io/sql.pyc\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1549\u001b[0m             \u001b[0mex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDatabaseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Execution failed on sql '%s': %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1550\u001b[0;31m             \u001b[0mraise_with_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/danielcphelps/anaconda/lib/python2.7/site-packages/pandas/io/sql.pyc\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1537\u001b[0m                 \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1538\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1539\u001b[0;31m                 \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1540\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcur\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1541\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDatabaseError\u001b[0m: Execution failed on sql '\nwith ce as\n(\n  select\n    icustay_id, charttime, itemid, valuenum\n  from chartevents\n  -- specify what data we want from chartevents\n  where itemid in\n  (\n  211, -- Heart Rate\n  618, --\tRespiratory Rate\n  615 --\tResp Rate (Total)\n  )\n  -- how did we know heart rates were stored using ITEMID 211? Simple, we looked in D_ITEMS!\n  -- Try it for yourself: select * from d_items where lower(label) like '%heart rate%'\n)\nselect\n  -- ICUSTAY_ID identifies each unique patient ICU stay\n  -- note that if the same person stays in the ICU more than once, each stay would have a *different* ICUSTAY_ID\n  -- however, since it's the same person, all those stays would have the same SUBJECT_ID\n  ie.icustay_id\n\n  -- this is the outcome of interest: in-hospital mortality\n  , max(adm.HOSPITAL_EXPIRE_FLAG) as OUTCOME\n\n  -- this is a case statement - essentially an \"if, else\" clause\n  , min(\n      case\n        -- if the itemid is 211\n        when itemid = 211\n          -- then return the actual value stored in VALUENUM\n          then valuenum\n        -- otherwise, return 'null', which is SQL standard for an empty value\n        else null\n      -- end the case statement\n      end\n    ) as HeartRate_Min\n\n    -- note we wrapped the above in \"min()\"\n    -- this takes the minimum of all values inside, and *ignores* nulls\n    -- by calling this on our case statement, we are ignoring all values except those with ITEMID = 211\n    -- since ITEMID 211 are heart rates, we take the minimum of only heart rates\n\n  , max(case when itemid = 211 then valuenum else null end) as HeartRate_Max\n  , min(case when itemid in (615,618) then valuenum else null end) as RespRate_Min\n  , max(case when itemid in (615,618) then valuenum else null end) as RespRate_Max\nfrom icustays ie\n\n-- join to the admissions table to get hospital outcome\ninner join admissions adm\n  on ie.hadm_id = adm.hadm_id\n\n-- join to the chartevents table to get the observations\nleft join ce\n  -- match the tables on the patient identifier\n  on ie.icustay_id = ce.icustay_id\n  -- and require that the observation be made after the patient is admitted to the ICU\n  and ce.charttime >= ie.intime\n  -- and *before* their admission time + 1 day, i.e. the observation must be made on their first day in the ICU\n  and ce.charttime <= ie.intime + interval '1' day\ngroup by ie.icustay_id\norder by ie.icustay_id\n': near \"'1'\": syntax error"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "with ce as\n",
    "(\n",
    "  select\n",
    "    icustay_id, charttime, itemid, valuenum\n",
    "  from chartevents\n",
    "  -- specify what data we want from chartevents\n",
    "  where itemid in\n",
    "  (\n",
    "  211, -- Heart Rate\n",
    "  618, --\tRespiratory Rate\n",
    "  615 --\tResp Rate (Total)\n",
    "  )\n",
    "  -- how did we know heart rates were stored using ITEMID 211? Simple, we looked in D_ITEMS!\n",
    "  -- Try it for yourself: select * from d_items where lower(label) like '%heart rate%'\n",
    ")\n",
    "select\n",
    "  -- ICUSTAY_ID identifies each unique patient ICU stay\n",
    "  -- note that if the same person stays in the ICU more than once, each stay would have a *different* ICUSTAY_ID\n",
    "  -- however, since it's the same person, all those stays would have the same SUBJECT_ID\n",
    "  ie.icustay_id\n",
    "\n",
    "  -- this is the outcome of interest: in-hospital mortality\n",
    "  , max(adm.HOSPITAL_EXPIRE_FLAG) as OUTCOME\n",
    "\n",
    "  -- this is a case statement - essentially an \"if, else\" clause\n",
    "  , min(\n",
    "      case\n",
    "        -- if the itemid is 211\n",
    "        when itemid = 211\n",
    "          -- then return the actual value stored in VALUENUM\n",
    "          then valuenum\n",
    "        -- otherwise, return 'null', which is SQL standard for an empty value\n",
    "        else null\n",
    "      -- end the case statement\n",
    "      end\n",
    "    ) as HeartRate_Min\n",
    "\n",
    "    -- note we wrapped the above in \"min()\"\n",
    "    -- this takes the minimum of all values inside, and *ignores* nulls\n",
    "    -- by calling this on our case statement, we are ignoring all values except those with ITEMID = 211\n",
    "    -- since ITEMID 211 are heart rates, we take the minimum of only heart rates\n",
    "\n",
    "  , max(case when itemid = 211 then valuenum else null end) as HeartRate_Max\n",
    "  , min(case when itemid in (615,618) then valuenum else null end) as RespRate_Min\n",
    "  , max(case when itemid in (615,618) then valuenum else null end) as RespRate_Max\n",
    "from icustays ie\n",
    "\n",
    "-- join to the admissions table to get hospital outcome\n",
    "inner join admissions adm\n",
    "  on ie.hadm_id = adm.hadm_id\n",
    "\n",
    "-- join to the chartevents table to get the observations\n",
    "left join ce\n",
    "  -- match the tables on the patient identifier\n",
    "  on ie.icustay_id = ce.icustay_id\n",
    "  -- and require that the observation be made after the patient is admitted to the ICU\n",
    "  and ce.charttime >= ie.intime\n",
    "  -- and *before* their admission time + 1 day, i.e. the observation must be made on their first day in the ICU\n",
    "  and ce.charttime <= ie.intime + interval '1' day\n",
    "group by ie.icustay_id\n",
    "order by ie.icustay_id\n",
    "\"\"\"\n",
    "conn = sqlite3.connect('/Users/danielcphelps/Boxcryptor/Google Drive/daniel.c.phelps/Research/HealthcareAnalytics/mimic-workshop/data/mimicdata.sqlite')\n",
    "data = pd.read_sql_query(query,conn)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# close the connection as we are done loading data from server\n",
    "cur.close()\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# move from a data frame into a numpy array\n",
    "X = data.values\n",
    "y = X[:,1]\n",
    "\n",
    "# delete first 2 columns: the ID and the outcome\n",
    "X = np.delete(X,0,axis=1)\n",
    "X = np.delete(X,0,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.784267912773\n",
      "AUROC = 0.642288212031\n",
      "\n",
      "Confusion matrix\n",
      "[[977  17]\n",
      " [260  30]]\n",
      "\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.98      0.88       994\n",
      "        1.0       0.64      0.10      0.18       290\n",
      "\n",
      "avg / total       0.76      0.78      0.72      1284\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate a logistic regression model using an 80%-20% training/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# impute mean for missing values\n",
    "imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "imp.fit(X_train)\n",
    "\n",
    "X_train = imp.transform(X_train)\n",
    "X_test = imp.transform(X_test)\n",
    "\n",
    "model = LogisticRegression(fit_intercept=True)\n",
    "model = model.fit(X_train, y_train)\n",
    "\n",
    "# predict class labels for the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# generate class probabilities\n",
    "y_prob = model.predict_proba(X_test)\n",
    "\n",
    "# generate evaluation metrics\n",
    "print('Accuracy = {}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
    "print('AUROC = {}'.format(metrics.roc_auc_score(y_test, y_prob[:, 1])))\n",
    "\n",
    "print('\\nConfusion matrix')\n",
    "print(metrics.confusion_matrix(y_test, y_pred))\n",
    "print('\\nClassification report')\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC for all folds:\n",
      "[ 0.632241    0.66711432  0.65462583  0.63505984  0.64856111]\n",
      "Average AUROC across folds:\n",
      "0.647520418729\n"
     ]
    }
   ],
   "source": [
    "# evaluate a logistic regression with L1 regularization\n",
    "\n",
    "# evaluate the model using 5-fold cross-validation\n",
    "# see: http://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "# for list of scoring parameters\n",
    "\n",
    "estimator = Pipeline([(\"imputer\", Imputer(missing_values='NaN',\n",
    "                                          strategy=\"mean\",\n",
    "                                          axis=0)),\n",
    "                      (\"regression\", LogisticRegressionCV(penalty='l1',\n",
    "                                                          cv=5,\n",
    "                                                          scoring='roc_auc',\n",
    "                                                          solver='liblinear'))])\n",
    "\n",
    "scores = cross_val_score(estimator\n",
    "                         , X, y\n",
    "                         , scoring='roc_auc', cv=5)\n",
    "\n",
    "\n",
    "print('AUROC for all folds:')\n",
    "print(scores)\n",
    "print('Average AUROC across folds:')\n",
    "print(scores.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
